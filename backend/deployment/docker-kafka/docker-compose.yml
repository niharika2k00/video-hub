services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.15
    container_name: zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      # ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - ./.zookeeper-data/data:/var/lib/zookeeper/data
      - ./.zookeeper-data/logs:/var/lib/zookeeper/log

  # kafka broker
  kafka:
    image: confluentinc/cp-kafka:7.2.15
    container_name: kafka
    restart: always
    ports:
      - "9092:9092" # For internal access
      - "9093:9093" # For external access
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 # when access internally from within the docker container
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT

      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # Retention policies (2 days = 172800000 ms)
      KAFKA_LOG_RETENTION_HOURS: 48 # 2 days in hours
      KAFKA_LOG_RETENTION_BYTES: -1 # Disable size-based retention
      KAFKA_LOG_SEGMENT_MS: 86400000 # 1 day segment size
      KAFKA_LOG_CLEANUP_POLICY: delete

      # Other configurations
      KAFKA_REPLICA_FETCH_MAX_BYTES: 20000000 # 20 MB
      KAFKA_MESSAGE_MAX_BYTES: 20000000 # 20 MB
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
    depends_on:
      - zookeeper
    volumes:
      - ./.kafka-data/data:/var/lib/kafka/data

  topic-init:
    image: confluentinc/cp-kafka:7.2.15
    container_name: topic-init
    depends_on:
      - kafka
    command: >
      /bin/bash -c "
      echo "Waiting for Kafka to be ready...";
      for i in {1..20}; do
        kafka-topics --bootstrap-server kafka:9092 --list && break || sleep 5;
        echo "Retrying...";
      done &&
      kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 2 --topic testtopic &&
      kafka-topics --list --bootstrap-server kafka:9092
      "

  # Cleanup service - runs daily to clean old data
  cleanup:
    image: confluentinc/cp-kafka:7.2.15
    container_name: kafka-cleanup
    restart: unless-stopped
    depends_on:
      - kafka
    command: >
      /bin/bash -c "
      while true; do
        echo "Running cleanup at $(date)";
        kafka-log-dirs --bootstrap-server kafka:9092 --describe --json | jq '.brokers[].logDirs[].partitions[] | select(.size > 0)';
        sleep 86400;  # Run every 24 hours
      done
      "

  # Producer and consumer containers are temporary - they run once, send/consume messages, then exit.
  # Use official image edenhill/kcat:1.7.1 - lightweight Kafka client
  producer:
    image: edenhill/kcat:1.7.1
    container_name: kafka-producer
    depends_on:
      - kafka
    entrypoint: >
      sh -c "
      echo "Producing messages to the topic...";
      sleep 10;
      echo "Message 1: Hello Kafka!" | kcat -P -b kafka:9092 -t testtopic &&
      echo "Message 2: Kafka is awesome!" | kcat -P -b kafka:9092 -t testtopic
      "

  consumer:
    image: edenhill/kcat:1.7.1
    container_name: kafka-consumer
    depends_on:
      - kafka
    entrypoint: >
      sh -c "
      echo "Consuming messages from the topic...";
      sleep 20;
      kcat -C -b kafka:9092 -t testtopic -o beginning
      "

# Check container logs
# docker logs kafka-producer
# docker logs kafka-consumer
